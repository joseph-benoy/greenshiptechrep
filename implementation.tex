\section{Implementation}\label{sec:implementation}
We use \Call{Solve}{} from Algorithm~\ref{alg:solve} to find the projection of $S$ w.r.t. $Y\subseteq \VAR(S)$. The method \Call{Project}{} is presented below in Algorithm~\ref{alg:project}. It consists of steps of preprocessing the system, doing Gauss-elimination and doing FM-elimination on the system. After each FM-elimination of a variable some (timewise) ``cheap'' preprocessing steps are done, and we also make sure to remove linearly dependent (in)equalities as well. 
Hence \Call{CleanUp}{} consists of %the (timewise) ``cheap'' preprocessing steps plus \Call{RemoveQuasiIneqs}{}, i.e. 
Algorithm~\ref{alg:prep} minus the calls to \Call{ForcedByBounds}{} and \Call{RemoveLessStrictIneqs}{}.
The reason we do not simply use \Call{Preprocess}{} is that the two above mentioned subprocedures in experience 
are more time consuming than the others and prior results showed a too little effect compared to the time taken.

After this, we remove redundant inequalities (we check only the newly added inequalities) using \Call{RemoveRedundancy}{} from Algorithm~\ref{alg:manager}. 
In \Call{RemoveRedundancy}{}, each step of doing parallel or sequential redundancy checks, respectively, are potentially repeated a number of times (or until the system does not change) depending on the values in the considered model, since ``off''-numbers (according to experience) are more likely to cause bad $\kappa$-values. If there are many inequalities resulting in bad $\kappa$-values, we would then like to test them again (after other redundant inequalities have been removed), since the removal of other inequalities can lead to a better $\kappa$-value when the inequality is re-evaluated.    
Due to the sometimes large number of inequalities that we do not know the redundancy staus of (because of a bad $\kappa$-value, that do not change during the repeated checks for redundancy), in some runs of the method we also start the FM-elimination-step in \Call{Project}{} with a full sequential redundancy check.

\begin{algorithm}\caption{Overview of the method for projecting the variables $Y$ from an (in)equality system  $S$.}\label{alg:project}
\begin{algorithmic}[1]
\Function{Project}{S,Y}
	\State $S'\gets S$
	\State $S'\gets\Call{Preprocess}{S',Y}$\Comment See Algorithm~\ref{alg:prep}
	\State $S'\gets\Call{Gauss-Elim}{S',Y}$\Comment See Algorithm~\ref{alg:Gauss} 
	\State $S'\gets \Call{FM-Elim*}{S',Y}$\Comment FM-elimination with redundancy removal (see below)
\EndFunction
\State
\Function{FM-Elim*}{$S,Y$}
	\State  $S'\gets S$, $Y'\gets Y$
	\While{ $Y'\neq \emptyset$ }
		\State $x\gets$ \Call{ChooseVariableToDelete}{$Y'$, $S'$}
		\State $S''\gets(\mi{Zero}_{S'}(x))_{\VAR(S')\setminus\{x\}}$
		\State $S' \gets$ \Call{FM-ElimVar}{$S'$, $x$} \Comment Algorithm~\ref{alg:FMBasic}
		\State Remove $x$ from $Y'$
		\State $S'\gets\Call{CleanUP}{S',Y}$
	%	\State $S'\gets \Call{RemoveQuasiIneqs}{S',Y}$
		\State $S'\gets \Call{RemoveRedundancy}{S', S'\setminus S'', \text{available threads}}$ 	\Comment Algorithm~\ref{alg:manager}\label{ln:projx}
	\EndWhile
	\State \Return $S'$
\EndFunction
\end{algorithmic}
\end{algorithm}

{In our implementation of the program we use rationals for the coefficients and right-hand-sides}.

$\epsilon$ in Section~\ref{sec:uncertainty} is set to $0.01$, $\epsilon' = 0.000001$, and $\mathcal{K} = 10^{14}$.

{It should be noted, that because we use the almost redundant criteria when doing (sequential) redundancy, the system $S'$ returned in line~\ref{ln:projx} is no longer completely identical to $\proj_x(S)$; $S'$ will most likely be an overapproximation of the projection. However, as previously mentioned, the parameters of a problem -- and this indeed holds for the particular problem we have considered -- are not necessarily very accurate, and small discrepancies between the returned projection and the actual projection is acceptable. It still remains to be shown that the overapproximation is not ``too big'' according to a given criterion.}
\\
\\
The program was implemented in Java.

In the implementation, we have used a list, not a set, for representing the (in)equalities in a system. Thus, at a given point, the (in)equality system $S$ might contain two (in)equalities $c$ and $c'$ for which $\vea(c)=\vea(c')$. However, either $c$ or $c'$ will be removed in the preprocessing/clean up step (when removing linearly dependent (in)equalities), and this does not influence the correctness of the algorithm(s).

We also normalize the (in)equalities in the inequality system such that the smallest absolute value of the coefficients is $1$. This also makes it easier to detect linear dependencies. 
\\
\\
We want to point out here, that the implemented program is non-deterministic due to a number of factors. 

Firstly, the almost redundant-criteria for removing inequalities in the sequential redundancy removal means that the order in which the inequalities are checked, matters. 
For two runs (on the same input system) to result in the exact  same projection, the variables must be projected in the same order, and at each variable elimination, the produced inequalities must be added in the same order (or checked for redundancy in the same order), and the redundancy check using CPLEX must result in the same yes/no answer (and $\kappa$-value). %This is in principle possible to achieve by having fixed orders of variables e.t.c. and setting some properties for CPLEX}.
 
Making use of parallel redundancy check means that when an inequality from a system is checked for redundancy in two different runs, another inequality might have been deemed redundant by another checker and hence have been removed in one run, while it is not in the other run (because the checker finished later). This can influence how long the check of the current inequality takes and influence the $\kappa$-value, so this effect can propagate. In the end, this might cause the set of removed (in)equalities to vary in the two runs altogether (because some inequalities in reality are redundant but cannot be determined to be so). 

Likewise, we make use of an in-build mechanism in Java for parallelism, namely streams. These are used for example when using the heuristic for finding out which variable should be removed. Again, this can of course be avoided.

In conclusion, with careful ordering of variables e.t.c., settings of parameters for CPLEX and avoidance of parallelism, non-determinism could possibly be avoided, but will most likely also be less efficient.  

%We go through the inequalities to be checked again a number of times (parallel) or until none changes status(/becomes redundant), and we do the same with the sequential checks. Also, (sometimes) we check all inequalities at the beginning of each parallel section and at the beginning of each sequential section.

%\red{In reality, each checker has a list of redundant inequalities in its class, which is updated (synchroniously) while its run/solve method is running. This list is copied and emptied (synchroniously) at each new beginning of the while-loop, so that we only have to remove what has been found redundant since last time redundant inequalities were removed. 
%Also, in reality, the next inequality to handle is returned by the function that handles the result.}
%